2024-07-29 13:56:57,206	INFO worker.py:1788 -- Started a local Ray instance.
2024-07-29 13:57:00,995	INFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
2024-07-29 13:57:01,013	WARNING tune.py:902 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.
[36m(train pid=3767028)[0m /home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/task_train_prep.py:104: UserWarning: 
[36m(train pid=3767028)[0m The version_base parameter is not specified.
[36m(train pid=3767028)[0m Please specify a compatability version level, or None.
[36m(train pid=3767028)[0m Will assume defaults for version 1.1
[36m(train pid=3767028)[0m   with hydra.initialize(
[36m(train pid=3767028)[0m /home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/task_train_prep.py:104: UserWarning: 
[36m(train pid=3767028)[0m The version_base parameter is not specified.
[36m(train pid=3767028)[0m Please specify a compatability version level, or None.
[36m(train pid=3767028)[0m Will assume defaults for version 1.1
[36m(train pid=3767028)[0m   with hydra.initialize(
[36m(train pid=3767028)[0m [rank: 0] Seed set to 0
2024-07-29 13:57:06,383	ERROR tune_controller.py:1331 -- Trial task failed for trial train_f15bd_00000
Traceback (most recent call last):
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/worker.py", line 2656, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/worker.py", line 871, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(AttributeError): [36mray::ImplicitFunc.train()[39m (pid=3767014, ip=172.17.6.66, actor_id=03b864c18c1fd6ec3087811301000000, repr=train)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 331, in train
    raise skipped from exception_cause(skipped)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/air/_internal/util.py", line 98, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 248, in _trainable_func
    output = fn()
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/task_train_prep.py", line 162, in train
    model.init_model(n_inputs, n_outputs)
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/model/gnode.py", line 37, in init_model
    self.generator = gatedMLPCell(
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/model/gnode.py", line 87, in __init__
    layers_gat.append(nn.ReLu())
AttributeError: module 'torch.nn' has no attribute 'ReLu'
2024-07-29 13:57:06,454	ERROR tune_controller.py:1331 -- Trial task failed for trial train_f15bd_00002
Traceback (most recent call last):
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/worker.py", line 2656, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/worker.py", line 871, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(AttributeError): [36mray::ImplicitFunc.train()[39m (pid=3767028, ip=172.17.6.66, actor_id=7df416b1b89cdf29f174acf301000000, repr=train)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 331, in train
    raise skipped from exception_cause(skipped)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/air/_internal/util.py", line 98, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 248, in _trainable_func
    output = fn()
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/task_train_prep.py", line 162, in train
    model.init_model(n_inputs, n_outputs)
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/model/gnode.py", line 37, in init_model
    self.generator = gatedMLPCell(
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/model/gnode.py", line 87, in __init__
    layers_gat.append(nn.ReLu())
AttributeError: module 'torch.nn' has no attribute 'ReLu'
2024-07-29 13:57:06,466	ERROR tune_controller.py:1331 -- Trial task failed for trial train_f15bd_00004
Traceback (most recent call last):
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/worker.py", line 2656, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/worker.py", line 871, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(AttributeError): [36mray::ImplicitFunc.train()[39m (pid=3767049, ip=172.17.6.66, actor_id=c93b7156ddb5091dfd0f477301000000, repr=train)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 331, in train
    raise skipped from exception_cause(skipped)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/air/_internal/util.py", line 98, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 248, in _trainable_func
    output = fn()
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/task_train_prep.py", line 162, in train
    model.init_model(n_inputs, n_outputs)
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/model/gnode.py", line 37, in init_model
    self.generator = gatedMLPCell(
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/model/gnode.py", line 87, in __init__
    layers_gat.append(nn.ReLu())
AttributeError: module 'torch.nn' has no attribute 'ReLu'
2024-07-29 13:57:06,608	ERROR tune_controller.py:1331 -- Trial task failed for trial train_f15bd_00001
Traceback (most recent call last):
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/worker.py", line 2656, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/worker.py", line 871, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(AttributeError): [36mray::ImplicitFunc.train()[39m (pid=3767027, ip=172.17.6.66, actor_id=af93aeae5aecff43d73f4ad701000000, repr=train)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 331, in train
    raise skipped from exception_cause(skipped)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/air/_internal/util.py", line 98, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 248, in _trainable_func
    output = fn()
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/task_train_prep.py", line 162, in train
    model.init_model(n_inputs, n_outputs)
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/model/gnode.py", line 37, in init_model
    self.generator = gatedMLPCell(
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/model/gnode.py", line 87, in __init__
    layers_gat.append(nn.ReLu())
AttributeError: module 'torch.nn' has no attribute 'ReLu'
2024-07-29 13:57:06,711	ERROR tune_controller.py:1331 -- Trial task failed for trial train_f15bd_00003
Traceback (most recent call last):
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/worker.py", line 2656, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/worker.py", line 871, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(AttributeError): [36mray::ImplicitFunc.train()[39m (pid=3767036, ip=172.17.6.66, actor_id=80592bce0f8c274a6c8d751c01000000, repr=train)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 331, in train
    raise skipped from exception_cause(skipped)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/air/_internal/util.py", line 98, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 248, in _trainable_func
    output = fn()
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/task_train_prep.py", line 162, in train
    model.init_model(n_inputs, n_outputs)
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/model/gnode.py", line 37, in init_model
    self.generator = gatedMLPCell(
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/model/gnode.py", line 87, in __init__
    layers_gat.append(nn.ReLu())
AttributeError: module 'torch.nn' has no attribute 'ReLu'
[36m(train pid=3767524)[0m /home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/task_train_prep.py:104: UserWarning: [32m [repeated 10x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(train pid=3767524)[0m The version_base parameter is not specified.[32m [repeated 10x across cluster][0m
[36m(train pid=3767524)[0m Please specify a compatability version level, or None.[32m [repeated 10x across cluster][0m
[36m(train pid=3767524)[0m Will assume defaults for version 1.1[32m [repeated 10x across cluster][0m
[36m(train pid=3767524)[0m   with hydra.initialize([32m [repeated 10x across cluster][0m
2024-07-29 13:57:10,839	ERROR tune_controller.py:1331 -- Trial task failed for trial train_f15bd_00005
Traceback (most recent call last):
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/worker.py", line 2656, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/_private/worker.py", line 871, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(AttributeError): [36mray::ImplicitFunc.train()[39m (pid=3767524, ip=172.17.6.66, actor_id=3d0d85783bd29ebc217237c101000000, repr=train)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 331, in train
    raise skipped from exception_cause(skipped)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/air/_internal/util.py", line 98, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 45, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 248, in _trainable_func
    output = fn()
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/trainable/util.py", line 130, in inner
    return trainable(config, **fn_kwargs)
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/task_train_prep.py", line 162, in train
    model.init_model(n_inputs, n_outputs)
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/model/gnode.py", line 37, in init_model
    self.generator = gatedMLPCell(
  File "/home/ad2002/ComputationThruDynamicsBenchmark/ctd/task_modeling/model/gnode.py", line 87, in __init__
    layers_gat.append(nn.ReLu())
AttributeError: module 'torch.nn' has no attribute 'ReLu'
2024-07-29 13:57:10,860	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/scratch/gpfs/ad2002/content/runs/task-trained/20240729_gNODE_MultiTask_CDM12_simple_500epoch/train_2024-07-29_13-57-01' in 0.0194s.
Saving files to /scratch/gpfs/ad2002
╭──────────────────────────────────────────────────────────────╮
│ Configuration for experiment     train_2024-07-29_13-57-01   │
├──────────────────────────────────────────────────────────────┤
│ Search algorithm                 BasicVariantGenerator       │
│ Scheduler                        FIFOScheduler               │
│ Number of trials                 6                           │
╰──────────────────────────────────────────────────────────────╯

View detailed results here: /scratch/gpfs/ad2002/content/runs/task-trained/20240729_gNODE_MultiTask_CDM12_simple_500epoch/train_2024-07-29_13-57-01
To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts`

Trial status: 6 PENDING
Current time: 2024-07-29 13:57:01. Total running time: 0s
Logical resource usage: 4.0/48 CPUs, 0.8/1 GPUs (0.0/1.0 accelerator_type:A100)
╭─────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       ...per/learning_rate     params/batch_size │
├─────────────────────────────────────────────────────────────────────────────┤
│ train_f15bd_00000   PENDING                     0.01                     64 │
│ train_f15bd_00001   PENDING                     0.01                    128 │
│ train_f15bd_00002   PENDING                     0.01                    250 │
│ train_f15bd_00003   PENDING                     0.001                    64 │
│ train_f15bd_00004   PENDING                     0.001                   128 │
│ train_f15bd_00005   PENDING                     0.001                   250 │
╰─────────────────────────────────────────────────────────────────────────────╯

Trial train_f15bd_00002 started with configuration:
╭────────────────────────────────────────────────────────╮
│ Trial train_f15bd_00002 config                         │
├────────────────────────────────────────────────────────┤
│ env_sim/bin_size                                     5 │
│ env_sim/dataset_name                          CDM1CDM2 │
│ env_sim/dynamic_noise                              0.1 │
│ env_sim/loss_func                  SimpleMultiTaskLoss │
│ env_sim/noise                                      0.0 │
│ env_sim/task_list                     ['CDM1', 'CDM2'] │
│ env_task/bin_size                                    5 │
│ env_task/dataset_name                         CDM1CDM2 │
│ env_task/loss_func                 SimpleMultiTaskLoss │
│ env_task/noise                                     0.0 │
│ env_task/task_list                    ['CDM1', 'CDM2'] │
│ model/latent_size                                    5 │
│ params/batch_size                                  250 │
│ params/n_samples                                  2000 │
│ params/num_workers                                   5 │
│ task_wrapper/learning_rate                        0.01 │
│ task_wrapper/weight_decay                          0.1 │
│ trainer/log_every_n_steps                            8 │
│ trainer/max_epochs                                 500 │
╰────────────────────────────────────────────────────────╯

Trial train_f15bd_00000 started with configuration:
╭────────────────────────────────────────────────────────╮
│ Trial train_f15bd_00000 config                         │
├────────────────────────────────────────────────────────┤
│ env_sim/bin_size                                     5 │
│ env_sim/dataset_name                          CDM1CDM2 │
│ env_sim/dynamic_noise                              0.1 │
│ env_sim/loss_func                  SimpleMultiTaskLoss │
│ env_sim/noise                                      0.0 │
│ env_sim/task_list                     ['CDM1', 'CDM2'] │
│ env_task/bin_size                                    5 │
│ env_task/dataset_name                         CDM1CDM2 │
│ env_task/loss_func                 SimpleMultiTaskLoss │
│ env_task/noise                                     0.0 │
│ env_task/task_list                    ['CDM1', 'CDM2'] │
│ model/latent_size                                    5 │
│ params/batch_size                                   64 │
│ params/n_samples                                  2000 │
│ params/num_workers                                   5 │
│ task_wrapper/learning_rate                        0.01 │
│ task_wrapper/weight_decay                          0.1 │
│ trainer/log_every_n_steps                            8 │
│ trainer/max_epochs                                 500 │
╰────────────────────────────────────────────────────────╯

Trial train_f15bd_00004 started with configuration:
╭────────────────────────────────────────────────────────╮
│ Trial train_f15bd_00004 config                         │
├────────────────────────────────────────────────────────┤
│ env_sim/bin_size                                     5 │
│ env_sim/dataset_name                          CDM1CDM2 │
│ env_sim/dynamic_noise                              0.1 │
│ env_sim/loss_func                  SimpleMultiTaskLoss │
│ env_sim/noise                                      0.0 │
│ env_sim/task_list                     ['CDM1', 'CDM2'] │
│ env_task/bin_size                                    5 │
│ env_task/dataset_name                         CDM1CDM2 │
│ env_task/loss_func                 SimpleMultiTaskLoss │
│ env_task/noise                                     0.0 │
│ env_task/task_list                    ['CDM1', 'CDM2'] │
│ model/latent_size                                    5 │
│ params/batch_size                                  128 │
│ params/n_samples                                  2000 │
│ params/num_workers                                   5 │
│ task_wrapper/learning_rate                       0.001 │
│ task_wrapper/weight_decay                          0.1 │
│ trainer/log_every_n_steps                            8 │
│ trainer/max_epochs                                 500 │
╰────────────────────────────────────────────────────────╯

Trial train_f15bd_00001 started with configuration:
╭────────────────────────────────────────────────────────╮
│ Trial train_f15bd_00001 config                         │
├────────────────────────────────────────────────────────┤
│ env_sim/bin_size                                     5 │
│ env_sim/dataset_name                          CDM1CDM2 │
│ env_sim/dynamic_noise                              0.1 │
│ env_sim/loss_func                  SimpleMultiTaskLoss │
│ env_sim/noise                                      0.0 │
│ env_sim/task_list                     ['CDM1', 'CDM2'] │
│ env_task/bin_size                                    5 │
│ env_task/dataset_name                         CDM1CDM2 │
│ env_task/loss_func                 SimpleMultiTaskLoss │
│ env_task/noise                                     0.0 │
│ env_task/task_list                    ['CDM1', 'CDM2'] │
│ model/latent_size                                    5 │
│ params/batch_size                                  128 │
│ params/n_samples                                  2000 │
│ params/num_workers                                   5 │
│ task_wrapper/learning_rate                        0.01 │
│ task_wrapper/weight_decay                          0.1 │
│ trainer/log_every_n_steps                            8 │
│ trainer/max_epochs                                 500 │
╰────────────────────────────────────────────────────────╯

Trial train_f15bd_00003 started with configuration:
╭────────────────────────────────────────────────────────╮
│ Trial train_f15bd_00003 config                         │
├────────────────────────────────────────────────────────┤
│ env_sim/bin_size                                     5 │
│ env_sim/dataset_name                          CDM1CDM2 │
│ env_sim/dynamic_noise                              0.1 │
│ env_sim/loss_func                  SimpleMultiTaskLoss │
│ env_sim/noise                                      0.0 │
│ env_sim/task_list                     ['CDM1', 'CDM2'] │
│ env_task/bin_size                                    5 │
│ env_task/dataset_name                         CDM1CDM2 │
│ env_task/loss_func                 SimpleMultiTaskLoss │
│ env_task/noise                                     0.0 │
│ env_task/task_list                    ['CDM1', 'CDM2'] │
│ model/latent_size                                    5 │
│ params/batch_size                                   64 │
│ params/n_samples                                  2000 │
│ params/num_workers                                   5 │
│ task_wrapper/learning_rate                       0.001 │
│ task_wrapper/weight_decay                          0.1 │
│ trainer/log_every_n_steps                            8 │
│ trainer/max_epochs                                 500 │
╰────────────────────────────────────────────────────────╯

Trial train_f15bd_00000 errored after 0 iterations at 2024-07-29 13:57:06. Total running time: 5s
Error file: /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts/0_batch_size=64,learning_rate=0.0100/error.txt

Trial train_f15bd_00002 errored after 0 iterations at 2024-07-29 13:57:06. Total running time: 5s
Error file: /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts/2_batch_size=250,learning_rate=0.0100/error.txt

Trial train_f15bd_00004 errored after 0 iterations at 2024-07-29 13:57:06. Total running time: 5s
Error file: /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts/4_batch_size=128,learning_rate=0.0010/error.txt

Trial train_f15bd_00001 errored after 0 iterations at 2024-07-29 13:57:06. Total running time: 5s
Error file: /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts/1_batch_size=128,learning_rate=0.0100/error.txt

Trial train_f15bd_00003 errored after 0 iterations at 2024-07-29 13:57:06. Total running time: 5s
Error file: /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts/3_batch_size=64,learning_rate=0.0010/error.txt

Trial train_f15bd_00005 started with configuration:
╭────────────────────────────────────────────────────────╮
│ Trial train_f15bd_00005 config                         │
├────────────────────────────────────────────────────────┤
│ env_sim/bin_size                                     5 │
│ env_sim/dataset_name                          CDM1CDM2 │
│ env_sim/dynamic_noise                              0.1 │
│ env_sim/loss_func                  SimpleMultiTaskLoss │
│ env_sim/noise                                      0.0 │
│ env_sim/task_list                     ['CDM1', 'CDM2'] │
│ env_task/bin_size                                    5 │
│ env_task/dataset_name                         CDM1CDM2 │
│ env_task/loss_func                 SimpleMultiTaskLoss │
│ env_task/noise                                     0.0 │
│ env_task/task_list                    ['CDM1', 'CDM2'] │
│ model/latent_size                                    5 │
│ params/batch_size                                  250 │
│ params/n_samples                                  2000 │
│ params/num_workers                                   5 │
│ task_wrapper/learning_rate                       0.001 │
│ task_wrapper/weight_decay                          0.1 │
│ trainer/log_every_n_steps                            8 │
│ trainer/max_epochs                                 500 │
╰────────────────────────────────────────────────────────╯

Trial train_f15bd_00005 errored after 0 iterations at 2024-07-29 13:57:10. Total running time: 9s
Error file: /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts/5_batch_size=250,learning_rate=0.0010/error.txt

Trial status: 6 ERROR
Current time: 2024-07-29 13:57:10. Total running time: 9s
Logical resource usage: 1.0/48 CPUs, 0.2/1 GPUs (0.0/1.0 accelerator_type:A100)
╭─────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       ...per/learning_rate     params/batch_size │
├─────────────────────────────────────────────────────────────────────────────┤
│ train_f15bd_00000   ERROR                       0.01                     64 │
│ train_f15bd_00001   ERROR                       0.01                    128 │
│ train_f15bd_00002   ERROR                       0.01                    250 │
│ train_f15bd_00003   ERROR                       0.001                    64 │
│ train_f15bd_00004   ERROR                       0.001                   128 │
│ train_f15bd_00005   ERROR                       0.001                   250 │
╰─────────────────────────────────────────────────────────────────────────────╯

Number of errored trials: 6
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name            # failures   error file                                                                                                                                                                   │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_f15bd_00000              1   /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts/0_batch_size=64,learning_rate=0.0100/error.txt  │
│ train_f15bd_00001              1   /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts/1_batch_size=128,learning_rate=0.0100/error.txt │
│ train_f15bd_00002              1   /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts/2_batch_size=250,learning_rate=0.0100/error.txt │
│ train_f15bd_00003              1   /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts/3_batch_size=64,learning_rate=0.0010/error.txt  │
│ train_f15bd_00004              1   /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts/4_batch_size=128,learning_rate=0.0010/error.txt │
│ train_f15bd_00005              1   /tmp/ray/session_2024-07-29_13-56-55_491777_3763996/artifacts/2024-07-29_13-57-01/train_2024-07-29_13-57-01/driver_artifacts/5_batch_size=250,learning_rate=0.0010/error.txt │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Traceback (most recent call last):
  File "/home/ad2002/ComputationThruDynamicsBenchmark/examples/task_training/gnode_cdm.py", line 201, in <module>
    main(
  File "/home/ad2002/ComputationThruDynamicsBenchmark/examples/task_training/gnode_cdm.py", line 176, in main
    tune.run(
  File "/home/ad2002/.conda/envs/ctd/lib/python3.10/site-packages/ray/tune/tune.py", line 1035, in run
    raise TuneError("Trials did not complete", incomplete_trials)
ray.tune.error.TuneError: ('Trials did not complete', [train_f15bd_00000, train_f15bd_00001, train_f15bd_00002, train_f15bd_00003, train_f15bd_00004, train_f15bd_00005])
[36m(train pid=3767524)[0m [rank: 0] Seed set to 0[32m [repeated 5x across cluster][0m
